{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sentence_transformers.util import cos_sim\n",
    "import sys\n",
    "import key_words\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pickle\n",
    "def save_obj(obj:object,name:str):\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name:str)->object:\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/train_phase1.tsv\"\n",
    "df = pd.read_csv(train_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_marginal_relevance(doc_embedding: np.ndarray,\n",
    "        word_embeddings: np.ndarray,\n",
    "        words,\n",
    "        top_n = 5,\n",
    "        diversity = 0.8):\n",
    "    \"\"\"\n",
    "    Maximal Marginal Relevance algorithm for keyword extraction\n",
    "    * from KeyBERT repository on github\n",
    "\n",
    "    Args:\n",
    "        doc_embedding (numpy.ndarray): embedding of shape (1, 768)\n",
    "        word_embeddings (numpy.ndarray): embedding of shape (N, 768)\n",
    "        words (List[str]): list of words\n",
    "        top_n (Optional[int]): number of top words to extract\n",
    "        diversity (Optional[float]): diversity of top words to extract\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: list of top_n words with their scores\n",
    "    \"\"\"\n",
    "    # make sure 2d array\n",
    "    if doc_embedding.ndim == 1:\n",
    "        doc_embedding = doc_embedding.reshape(1, -1)\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "\n",
    "    word_doc_similarity = np.array(cos_sim(word_embeddings, doc_embedding)).clip(-1, 1).round(6)\n",
    "    word_similarity = np.array(cos_sim(word_embeddings, word_embeddings)).clip(-1, 1).round(6)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate maximal_marginal_relevance\n",
    "        mmr = (1-diversity) * candidate_similarities -\\\n",
    "            diversity * target_similarities.reshape(-1, 1)\n",
    "        # if return mmr is empty\n",
    "        if mmr.size == 0:\n",
    "            continue\n",
    "        mmr = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr)\n",
    "        candidates_idx.remove(mmr)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]\n",
    "\n",
    "def emb_keywords(keywords):\n",
    "    # x = np.array(list(map(lambda k: np.array(list(map(lambda x: BERT.model.encode(str(x)), k))),keywords)))\n",
    "    x = np.array(list(map(lambda k: np.array(list(map(lambda x: get_words_emb(str(x)), k))),keywords)))\n",
    "    if x.ndim == 3:\n",
    "        x = x.reshape(max(x.shape[1],x.shape[0]),x.shape[2])\n",
    "    return x\n",
    "\n",
    "def get_candidates(n_grams, doc):\n",
    "    x = list(map(lambda gram :\n",
    "        key_words.candidates_tokens(str(doc), n_gram_range=gram)\n",
    "        , n_grams))\n",
    "    return x\n",
    "\n",
    "def match_keywords(\n",
    "    keywords_emb:list[np.ndarray],\n",
    "    candidates_emb : list[np.ndarray],\n",
    "    thershold: float)\\\n",
    "        -> float:\n",
    "    \"\"\"\n",
    "    match keywords with candidates in a document\n",
    "\n",
    "    Args:\n",
    "        keywords_emb (List[np.ndarray]): list of keywords embeddings\n",
    "        candidates_emb (List[np.ndarray]): list of document's candidates embeddings\n",
    "        thershold (float): threshold\n",
    "\n",
    "    Returns:\n",
    "        float: score\n",
    "    \n",
    "    example:\n",
    "        >>> match_keywords(keywords_emb, candidates_emb, thershold=0.5)\n",
    "        >>> 0.8\n",
    "    \"\"\"\n",
    "    similarities = list(map(lambda cand:\n",
    "                    cos_sim(np.array(keywords_emb), cand.reshape(cand.shape[0],cand.shape[1])).__array__().max(axis=1).round(6).clip(-1, 1),\n",
    "                    candidates_emb))\n",
    "    return similarities\n",
    "\n",
    "def para_keywords_pipeline_output_dict(keywords,docs,n_gram_list,batch = 50):\n",
    "\n",
    "    def check_n_gram_dict(n_grams, doc, ind):\n",
    "        def fn(n_gram):\n",
    "            x = n_gram_dict[ind].get(n_gram)\n",
    "            if x is None:\n",
    "                x =  get_candidates([n_gram], doc)\n",
    "                n_gram_dict[ind][n_gram] = x\n",
    "                return x\n",
    "            else:\n",
    "                return x\n",
    "        return list(map(fn, n_grams))\n",
    "\n",
    "    n_docs = len(docs)\n",
    "    if n_docs < batch:\n",
    "        batch = n_docs\n",
    "    \n",
    "    n_gram_dict = {ind: {n_gram: None for n_gram in set([item for sublist in n_gram_list for item in sublist])} for ind ,doc in enumerate(docs)}\n",
    "\n",
    "    n_grams_list = []\n",
    "    students_candidates_list = []\n",
    "    keywords_embeddings_list = []\n",
    "    students_candidates_emb_list = []\n",
    "    times = []\n",
    "\n",
    "    # all model answers\n",
    "    for ind, ans in enumerate(keywords):\n",
    "        print(\"model answer\",ind)\n",
    "        t1 = time.perf_counter()\n",
    "        students_n_grams = key_words.get_n_grams(ans)\n",
    "        keywords_embeddings =  list(map(model.encode, ans))\n",
    "\n",
    "        students_candidates_list_s = []\n",
    "        students_candidates_emb_list_s = []\n",
    "        # do in batches\n",
    "        for i in range(0,n_docs,batch):\n",
    "            students_candidates = list(map(lambda doc:\n",
    "                            check_n_gram_dict(students_n_grams, doc[1], i+doc[0]),\n",
    "                            enumerate(docs[i:i+batch])))\n",
    "            students_candidates_emb =  list(map( lambda st: list(map( emb_keywords ,st)), students_candidates))\n",
    "            # students_candidates_emb =  list(map(emb_d, students_candidates))\n",
    "            students_candidates_list_s.extend(students_candidates)\n",
    "            students_candidates_emb_list_s.extend(students_candidates_emb)\n",
    "\n",
    "        if n_docs % batch != 0 and n_docs > batch:\n",
    "            students_candidates = list(map(lambda doc:\n",
    "                            check_n_gram_dict(students_n_grams, doc[1], i+doc[0]),\n",
    "                            enumerate(docs[i+batch:])))\n",
    "            students_candidates_emb =  list(map( lambda st: list(map( emb_keywords ,st)), students_candidates))\n",
    "\n",
    "            students_candidates_list_s.extend(students_candidates)\n",
    "            students_candidates_emb_list_s.extend(students_candidates_emb)\n",
    "\n",
    "        n_grams_list.append(students_n_grams)\n",
    "        keywords_embeddings_list.append(keywords_embeddings)\n",
    "        students_candidates_list.append(students_candidates_list_s)\n",
    "        students_candidates_emb_list.append(students_candidates_emb_list_s)\n",
    "        times.append(time.perf_counter() - t1)\n",
    "    return {\n",
    "        \"n_gram_dict\": n_gram_dict,\n",
    "        \"n_grams_list\": n_grams_list,\n",
    "        \"students_candidates_list\": students_candidates_list,\n",
    "        \"keywords_embeddings_list\": keywords_embeddings_list,\n",
    "        \"students_candidates_emb_list\": students_candidates_emb_list,\n",
    "        \"times\": times\n",
    "    }\n",
    "\n",
    "def get_words_emb(word):\n",
    "    if word in words_emb_dict:\n",
    "        return words_emb_dict[word]\n",
    "    else:\n",
    "        words_emb_dict[word] = model.encode(word)\n",
    "        return words_emb_dict[word]\n",
    "\n",
    "def grading(keywords_embeddings_list,students_candidates_emb_list,thershold=0.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        keywords_embeddings_list: list of list of list of embeddings\n",
    "        students_candidates_emb_list: list of list of list of embeddings\n",
    "        thershold: thershold for the similarity\n",
    "    Returns:\n",
    "        a list of list of list of grades\n",
    "    \"\"\"\n",
    "    grades = []\n",
    "    for i in range(len(keywords_embeddings_list)):\n",
    "        grades.append(np.array(list(map(lambda st_cand:\n",
    "                match_keywords(keywords_embeddings_list[i], st_cand,\n",
    "                thershold=thershold),\n",
    "                students_candidates_emb_list[i]\n",
    "                ))))\n",
    "    grades = np.array(list(map(lambda sim: (sim.__array__().max(axis=1) >thershold).sum(axis=1)/float(sim.shape[-1]) , grades)))\n",
    "    return grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emb_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_3_model_answers = load_obj('data/essaySet_3_model_answers')\n",
    "docs = df.query(f'EssaySet == {3}')[\"EssayText\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "425.2485177"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "docs_candidates = list(map(lambda ans: key_words.candidates_tokens(ans,n_gram_range=(2,3)),docs))\n",
    "docs_candidate_emb = list(map(lambda cand:model.encode(cand),docs_candidates))\n",
    "\n",
    "docs_emb = model.encode(docs)\n",
    "\n",
    "docs_keywords = list(map(lambda x: maximal_marginal_relevance(\n",
    "    x[0].reshape(1, -1),x[1],x[2],top_n=10 ,diversity=0.8),\n",
    "    zip(docs_emb,docs_candidate_emb,docs_candidates)))\n",
    "\n",
    "time.perf_counter() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_candidates = list(map(lambda ans: key_words.candidates_tokens(ans,n_gram_range=(2,3)),ess_3_model_answers))\n",
    "model_candidate_emb = list(map(lambda cand:model.encode(cand),model_candidates))\n",
    "keywords = list(map(lambda x: maximal_marginal_relevance(\n",
    "    x[0].reshape(1, -1),x[1],x[2],top_n=10,diversity=0.8),\n",
    "    zip(model.encode(ess_3_model_answers),\n",
    "    model_candidate_emb,model_candidates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.4907568000001\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "docs_keywords_emb = list(map(lambda x: model.encode(x),docs_keywords))\n",
    "print(time.perf_counter() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0961783000000196\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "keywords_emb = list(map(lambda x: model.encode(x),keywords))\n",
    "print(time.perf_counter() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = list(map(lambda model_emb:\n",
    "    list(map(lambda doc_emb: cos_sim(model_emb,doc_emb).__array__().max(axis=1), docs_keywords_emb)),keywords_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 (9, 384)\n",
      "125 (1, 384)\n",
      "226 (9, 384)\n",
      "266 (9, 384)\n",
      "551 (1, 384)\n",
      "560 (7, 384)\n",
      "609 (1, 384)\n",
      "897 (7, 384)\n",
      "906 (7, 384)\n",
      "1137 (5, 384)\n",
      "1453 (7, 384)\n",
      "1457 (7, 384)\n",
      "1633 (7, 384)\n",
      "1703 (7, 384)\n",
      "1887 (7, 384)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs_keywords_emb)):\n",
    "    if len(docs_keywords_emb[i]) !=10:\n",
    "        print(i,docs_keywords_emb[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1891, 10)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1891, 10)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s).max(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(s)):\n",
    "    for j in range(len(s[i])):\n",
    "        if s[i][j].shape[0] != 10:\n",
    "            print(i,j,s[i][j].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "1891\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(len(s))\n",
    "print(len(s[0]))\n",
    "print(s[0][-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "os.makedirs('data/new_results', exist_ok=True)\n",
    "save_obj(s,'data/new_results/essaySet_3_model_answers_grades')\n",
    "save_obj(docs_keywords,'data/new_results/essaySet_3_model_answers_keywords')\n",
    "save_obj(docs_keywords_emb,'data/new_results/essaySet_3_model_answers_keywords_emb')\n",
    "save_obj(docs_candidates,'data/new_results/essaySet_3_model_answers_candidates')\n",
    "save_obj(docs_candidate_emb,'data/new_results/essaySet_3_model_answers_candidates_emb')\n",
    "save_obj(keywords,'data/new_results/essaySet_3_model_answers_keywords')\n",
    "save_obj(keywords_emb,'data/new_results/essaySet_3_model_answers_keywords_emb')\n",
    "save_obj(model_candidates,'data/new_results/essaySet_3_model_answers_candidates')\n",
    "save_obj(model_candidate_emb,'data/new_results/essaySet_3_model_answers_candidates_emb')\n",
    "save_obj(docs_emb,'data/new_results/essaySet_3_model_answers_docs_emb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from data new folder\n",
    "s = load_obj('data/new_results/essaySet_3_model_answers_grades')\n",
    "# docs_keywords = load_obj('data/new_results/essaySet_3_model_answers_keywords')\n",
    "# docs_keywords_emb = load_obj('data/new_results/essaySet_3_model_answers_keywords_emb')\n",
    "# docs_candidates = load_obj('data/new_results/essaySet_3_model_answers_candidates')\n",
    "# docs_candidate_emb = load_obj('data/new_results/essaySet_3_model_answers_candidates_emb')\n",
    "# keywords = load_obj('data/new_results/essaySet_3_model_answers_keywords')\n",
    "# keywords_emb = load_obj('data/new_results/essaySet_3_model_answers_keywords_emb')\n",
    "# model_candidates = load_obj('data/new_results/essaySet_3_model_answers_candidates')\n",
    "# model_candidate_emb = load_obj('data/new_results/essaySet_3_model_answers_candidates_emb')\n",
    "# docs_emb = load_obj('data/new_results/essaySet_3_model_answers_docs_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 1891, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(s).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas china similar',\n",
       " 'specialists eats',\n",
       " 'pythons different places',\n",
       " 'live world',\n",
       " 'food koalas',\n",
       " 'bears australia specialists',\n",
       " 'different places',\n",
       " 'similar koala bears',\n",
       " 'eats type food',\n",
       " 'china similar koala']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_keywords_pipeline_output_dict(keywords,docs,n_gram_list,batch = 50):\n",
    "\n",
    "    def check_n_gram_dict(n_grams, doc, ind):\n",
    "        def fn(n_gram):\n",
    "            x = n_gram_dict[ind].get(n_gram)\n",
    "            if x is None:\n",
    "                x =  get_candidates([n_gram], doc)\n",
    "                n_gram_dict[ind][n_gram] = x\n",
    "                return x\n",
    "            else:\n",
    "                return x\n",
    "        return list(map(fn, n_grams))\n",
    "\n",
    "    n_docs = len(docs)\n",
    "    if n_docs < batch:\n",
    "        batch = n_docs\n",
    "    \n",
    "    n_gram_dict = {ind: {n_gram: None for n_gram in set([item for sublist in n_gram_list for item in sublist])} for ind ,doc in enumerate(docs)}\n",
    "\n",
    "    n_grams_list = []\n",
    "    students_candidates_list = []\n",
    "    keywords_embeddings_list = []\n",
    "    students_candidates_emb_list = []\n",
    "    times = []\n",
    "\n",
    "    # all model answers\n",
    "    for ind, ans in enumerate(keywords):\n",
    "        print(\"model answer\",ind)\n",
    "        t1 = time.perf_counter()\n",
    "        students_n_grams = key_words.get_n_grams(ans)\n",
    "        keywords_embeddings =  list(map(model.encode, ans))\n",
    "\n",
    "        students_candidates_list_s = []\n",
    "        students_candidates_emb_list_s = []\n",
    "        # do in batches\n",
    "        students_candidates = list(map(lambda ans: key_words.candidates_tokens(ans,n_gram_range=(3,3)),docs))\n",
    "\n",
    "        for i in range(0,n_docs,batch):\n",
    "            students_candidates_emb =  list(map( lambda st: list(map( emb_keywords ,st)), students_candidates))\n",
    "            # students_candidates_emb =  list(map(emb_d, students_candidates))\n",
    "            # students_candidates_list_s.extend(students_candidates)\n",
    "            students_candidates_emb_list_s.extend(students_candidates_emb)\n",
    "\n",
    "        if n_docs % batch != 0 and n_docs > batch:\n",
    "            # students_candidates = list(map(lambda doc:\n",
    "            #                 check_n_gram_dict(students_n_grams, doc[1], i+doc[0]),\n",
    "            #                 enumerate(docs[i+batch:])))\n",
    "            students_candidates_emb =  list(map( lambda st: list(map( emb_keywords ,st)), students_candidates))\n",
    "\n",
    "            # students_candidates_list_s.extend(students_candidates)\n",
    "            students_candidates_emb_list_s.extend(students_candidates_emb)\n",
    "\n",
    "        n_grams_list.append(students_n_grams)\n",
    "        keywords_embeddings_list.append(keywords_embeddings)\n",
    "        students_candidates_list.append(students_candidates)\n",
    "        # students_candidates_list.append(students_candidates_list_s)\n",
    "        students_candidates_emb_list.append(students_candidates_emb_list_s)\n",
    "        times.append(time.perf_counter() - t1)\n",
    "    return {\n",
    "        \"n_gram_dict\": n_gram_dict,\n",
    "        \"n_grams_list\": n_grams_list,\n",
    "        \"students_candidates_list\": students_candidates_list,\n",
    "        \"keywords_embeddings_list\": keywords_embeddings_list,\n",
    "        \"students_candidates_emb_list\": students_candidates_emb_list,\n",
    "        \"times\": times\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_l = [7]*10\n",
    "diversity_l = [0.6,0.6, 0.7,0.7,0.7,0.7,0.6,0.7,0.7,0.7]\n",
    "ngram_range_l = [(2,2),(2,2),(2,3),(2,3),(2,3),(2,3),(2,2),(2,3),(2,3),(2,3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = load_obj(f'data/results/new_keywords_res_essay_{1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tune threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "df_dict ={}\n",
    "\n",
    "for i in range(1,11):\n",
    "    df_dict['ess_'+str(i)+'_keywords'] = pd.DataFrame(df[df['EssaySet'] == i]['score_gn_1'])\n",
    "    # remove index\n",
    "    df_dict['ess_'+str(i)+'_keywords'].reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grading(keywords_emb, docs_keywords_emb, threshold = 0.5):\n",
    "    # return np.array(list(map(lambda model_ans:\n",
    "    #         np.array(list(map(lambda st: cos_sim(model_ans,st),docs_keywords_emb))),keywords_emb)))\n",
    "    s = list(map(lambda model_emb: \n",
    "    list(map(lambda doc_emb: cos_sim(model_emb,doc_emb).__array__().max(axis=1), docs_keywords_emb)),keywords_emb))\n",
    "    return np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwrds_model_1 = pd.DataFrame(np.array(s)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>score_gn_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837305</td>\n",
       "      <td>0.422338</td>\n",
       "      <td>0.573613</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>0.908609</td>\n",
       "      <td>0.471892</td>\n",
       "      <td>0.210106</td>\n",
       "      <td>0.686953</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.490941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857505</td>\n",
       "      <td>0.665791</td>\n",
       "      <td>0.639898</td>\n",
       "      <td>0.354995</td>\n",
       "      <td>0.594003</td>\n",
       "      <td>0.721938</td>\n",
       "      <td>0.413970</td>\n",
       "      <td>0.757992</td>\n",
       "      <td>0.672203</td>\n",
       "      <td>0.724064</td>\n",
       "      <td>0.501053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826201</td>\n",
       "      <td>0.452897</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>0.460464</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.651537</td>\n",
       "      <td>0.663255</td>\n",
       "      <td>0.855351</td>\n",
       "      <td>0.512069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892339</td>\n",
       "      <td>0.518353</td>\n",
       "      <td>0.639417</td>\n",
       "      <td>0.261189</td>\n",
       "      <td>0.735989</td>\n",
       "      <td>0.355202</td>\n",
       "      <td>0.320354</td>\n",
       "      <td>0.583015</td>\n",
       "      <td>0.751305</td>\n",
       "      <td>0.772607</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.539734</td>\n",
       "      <td>0.745090</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.585845</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.708652</td>\n",
       "      <td>0.186656</td>\n",
       "      <td>0.931490</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.837305  0.422338  0.573613  0.320906  0.908609  0.471892  0.210106   \n",
       "1  0.857505  0.665791  0.639898  0.354995  0.594003  0.721938  0.413970   \n",
       "2  0.826201  0.452897  0.695122  0.382576  0.695319  0.460464  0.404087   \n",
       "3  0.892339  0.518353  0.639417  0.261189  0.735989  0.355202  0.320354   \n",
       "4  0.970666  0.539734  0.745090  0.382576  0.772379  0.585845  0.404087   \n",
       "\n",
       "          7         8         9  score_gn_1  \n",
       "0  0.686953  0.560191  0.693069    0.490941  \n",
       "1  0.757992  0.672203  0.724064    0.501053  \n",
       "2  0.651537  0.663255  0.855351    0.512069  \n",
       "3  0.583015  0.751305  0.772607    1.000000  \n",
       "4  0.708652  0.186656  0.931490    0.000000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwrds_model_1 = pd.concat([kwrds_model_1,df_dict['ess_3_keywords']],axis=1)\n",
    "kwrds_model_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "X = kwrds_model_1.drop(['score_gn_1'],axis=1)\n",
    "# y = kwrds_model_1['Score1']\n",
    "y = kwrds_model_1['score_gn_1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "models_dict = {\n",
    "    'l_rg': LinearRegression(),\n",
    "    'l_svr': SVR(),\n",
    "    # 'l_knr': KNeighborsRegressor(),\n",
    "    'l_dt': DecisionTreeRegressor(),\n",
    "    'l_rf': RandomForestRegressor(),\n",
    "    'l_gb': GradientBoostingRegressor(),\n",
    "    'l_xgb': XGBRegressor(),\n",
    "    'l_lgb': LGBMRegressor(),\n",
    "    'l_cat': CatBoostRegressor(),\n",
    "    'l_mlp': MLPRegressor(),\n",
    "    # 'l_ada': AdaBoostRegressor(),\n",
    "    'l_gpr': GaussianProcessRegressor(),\n",
    "}\n",
    "for model_name, mod in models_dict.items():\n",
    "    mod.fit(X_train, y_train)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_rg MSE: 0.10710329118581877\n",
      "l_rg R2: 0.021957777432861758\n",
      "l_svr MSE: 0.11525404127518456\n",
      "l_svr R2: -0.05247296736247775\n",
      "l_dt MSE: 0.18152888799577185\n",
      "l_dt R2: -0.6576793776346037\n",
      "l_rf MSE: 0.11064180352932429\n",
      "l_rf R2: -0.010355090255014021\n",
      "l_gb MSE: 0.11253402993431857\n",
      "l_gb R2: -0.02763445952789656\n",
      "l_xgb MSE: 0.1363884140953992\n",
      "l_xgb R2: -0.24546712035991747\n",
      "l_lgb MSE: 0.1220731503505324\n",
      "l_lgb R2: -0.11474347765342596\n",
      "l_cat MSE: 0.11874790214478582\n",
      "l_cat R2: -0.08437808822675286\n",
      "l_mlp MSE: 0.10641849984983744\n",
      "l_mlp R2: 0.02821113186130697\n",
      "l_gpr MSE: 52.428854482718464\n",
      "l_gpr R2: -477.7680452878236\n"
     ]
    }
   ],
   "source": [
    "for mod_name, mod in models_dict.items():\n",
    "    print(f\"{mod_name} MSE:\", mean_squared_error(y_test, mod.predict(X_test)))\n",
    "    print(f\"{mod_name} R2:\", r2_score(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_rg MSE: 0.10537809470371774\n",
      "l_rg R2: 0.025248165515698417\n",
      "l_svr MSE: 0.08722567743753308\n",
      "l_svr R2: 0.19315879324423113\n",
      "l_dt MSE: 0.0001310035177059902\n",
      "l_dt R2: 0.9987882119185506\n",
      "l_rf MSE: 0.01453660504597451\n",
      "l_rf R2: 0.8655357882909464\n",
      "l_gb MSE: 0.07335172935643414\n",
      "l_gb R2: 0.3214933999916241\n",
      "l_xgb MSE: 0.002293362951184971\n",
      "l_xgb R2: 0.9787862956709255\n",
      "l_lgb MSE: 0.02080765381026746\n",
      "l_lgb R2: 0.8075283218974644\n",
      "l_cat MSE: 0.021107626415543927\n",
      "l_cat R2: 0.8047535626070219\n",
      "l_mlp MSE: 0.10489501761596165\n",
      "l_mlp R2: 0.029716649016102492\n",
      "l_gpr MSE: 0.0001989206398683152\n",
      "l_gpr R2: 0.9981599756650222\n"
     ]
    }
   ],
   "source": [
    "for mod_name, mod in models_dict.items():\n",
    "    print(f\"{mod_name} MSE:\", mean_squared_error(y_train, mod.predict(X_train)))\n",
    "    print(f\"{mod_name} R2:\", r2_score(y_train, mod.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "plot_importance(models_dict['l_xgb'],importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.48646\n",
      "[1]\tvalidation_0-error:0.48180\n",
      "[2]\tvalidation_0-error:0.45916\n",
      "[3]\tvalidation_0-error:0.48579\n",
      "[4]\tvalidation_0-error:0.49839\n",
      "MSE: 0.11034230613825845\n",
      "R2: -0.007620150079339139\n"
     ]
    }
   ],
   "source": [
    "eval_set = [(X_test, y_test)]\n",
    "xgb = XGBRegressor( max_depth=2,n_estimators=5, learning_rate=0.25, subsample=0.2, colsample_bytree=0.8,)\n",
    "# ,n_estimators=100,learning_rate=0.1)\n",
    "xgb.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, verbose=True)\n",
    "# plot training deviance\n",
    "# compute test set MSE\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwrds_model_1 = pd.DataFrame(np.array(s)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(df[df['EssaySet'] == 3]['Score1'])/4\n",
    "x.reset_index(drop=True, inplace=True)\n",
    "kwrds_model_1 = pd.concat([kwrds_model_1,x],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>Score1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837305</td>\n",
       "      <td>0.422338</td>\n",
       "      <td>0.573613</td>\n",
       "      <td>0.320906</td>\n",
       "      <td>0.908609</td>\n",
       "      <td>0.471892</td>\n",
       "      <td>0.210106</td>\n",
       "      <td>0.686953</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857505</td>\n",
       "      <td>0.665791</td>\n",
       "      <td>0.639898</td>\n",
       "      <td>0.354995</td>\n",
       "      <td>0.594003</td>\n",
       "      <td>0.721938</td>\n",
       "      <td>0.413970</td>\n",
       "      <td>0.757992</td>\n",
       "      <td>0.672203</td>\n",
       "      <td>0.724064</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.826201</td>\n",
       "      <td>0.452897</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>0.695319</td>\n",
       "      <td>0.460464</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.651537</td>\n",
       "      <td>0.663255</td>\n",
       "      <td>0.855351</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.892339</td>\n",
       "      <td>0.518353</td>\n",
       "      <td>0.639417</td>\n",
       "      <td>0.261189</td>\n",
       "      <td>0.735989</td>\n",
       "      <td>0.355202</td>\n",
       "      <td>0.320354</td>\n",
       "      <td>0.583015</td>\n",
       "      <td>0.751305</td>\n",
       "      <td>0.772607</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.970666</td>\n",
       "      <td>0.539734</td>\n",
       "      <td>0.745090</td>\n",
       "      <td>0.382576</td>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.585845</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.708652</td>\n",
       "      <td>0.186656</td>\n",
       "      <td>0.931490</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.837305  0.422338  0.573613  0.320906  0.908609  0.471892  0.210106   \n",
       "1  0.857505  0.665791  0.639898  0.354995  0.594003  0.721938  0.413970   \n",
       "2  0.826201  0.452897  0.695122  0.382576  0.695319  0.460464  0.404087   \n",
       "3  0.892339  0.518353  0.639417  0.261189  0.735989  0.355202  0.320354   \n",
       "4  0.970666  0.539734  0.745090  0.382576  0.772379  0.585845  0.404087   \n",
       "\n",
       "          7         8         9  Score1  \n",
       "0  0.686953  0.560191  0.693069    0.25  \n",
       "1  0.757992  0.672203  0.724064    0.25  \n",
       "2  0.651537  0.663255  0.855351    0.25  \n",
       "3  0.583015  0.751305  0.772607    0.50  \n",
       "4  0.708652  0.186656  0.931490    0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kwrds_model_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "X = kwrds_model_1.drop(['Score1'],axis=1)\n",
    "y = kwrds_model_1['Score1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    'l_rg': LinearRegression(),\n",
    "    'l_svr': SVR(),\n",
    "    'l_dt': DecisionTreeRegressor(),\n",
    "    'l_rf': RandomForestRegressor(),\n",
    "    'l_gb': GradientBoostingRegressor(),\n",
    "    'l_xgb': XGBRegressor(),\n",
    "    'l_lgb': LGBMRegressor(),\n",
    "    'l_cat': CatBoostRegressor(),\n",
    "    'l_mlp': MLPRegressor(),\n",
    "    'l_gpr': GaussianProcessRegressor(),\n",
    "}\n",
    "for model_name, mod in models_dict.items():\n",
    "    mod.fit(X_train, y_train)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_rg MSE: 0.02917206850394008\n",
      "l_rg R2: 0.02440439056501109\n",
      "l_svr MSE: 0.033348898260327955\n",
      "l_svr R2: -0.11528048543680725\n",
      "l_dt MSE: 0.052770448548812667\n",
      "l_dt R2: -0.7647914787113295\n",
      "l_rf MSE: 0.03057205528070947\n",
      "l_rf R2: -0.022415085143363322\n",
      "l_gb MSE: 0.03115390082480726\n",
      "l_gb R2: -0.04187362844530451\n",
      "l_xgb MSE: 0.03500002462505689\n",
      "l_xgb R2: -0.1704987717861055\n",
      "l_lgb MSE: 0.033972884512622856\n",
      "l_lgb R2: -0.1361483319525414\n",
      "l_cat MSE: 0.032574372105046524\n",
      "l_cat R2: -0.08937816327603687\n",
      "l_mlp MSE: 0.028978642055287943\n",
      "l_mlp R2: 0.030873112316029183\n",
      "l_gpr MSE: 19.0802420470046\n",
      "l_gpr R2: -637.0966905209482\n"
     ]
    }
   ],
   "source": [
    "for mod_name, mod in models_dict.items():\n",
    "    print(f\"{mod_name} MSE:\", mean_squared_error(y_test, mod.predict(X_test)))\n",
    "    print(f\"{mod_name} R2:\", r2_score(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1891, 384)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_1_emb = model.encode(df[df['EssaySet'] == 1][\"EssayText\"].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load essay set 1 model answers\n",
    "essay_set_1_answers = load_obj(f'data/essaySet_1_model_answers')\n",
    "set_1_answers_emb = model.encode(essay_set_1_answers)\n",
    "doc1_sims = cos_sim(set_1_answers_emb, np.array(docs_1_emb)).__array__().max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1_df = pd.concat([pd.DataFrame(doc1_sims), pd.DataFrame(df[df['EssaySet'] == 1]['score_gn_1'])],axis=1)\n",
    "doc1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "X = doc1_df.drop(['score_gn_1'],axis=1)\n",
    "y = doc1_df['score_gn_1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "models_dict = {\n",
    "    'l_rg': LinearRegression(),\n",
    "    'l_svr': SVR(),\n",
    "    'l_dt': DecisionTreeRegressor(),\n",
    "    'l_rf': RandomForestRegressor(),\n",
    "    'l_gb': GradientBoostingRegressor(),\n",
    "    'l_xgb': XGBRegressor(),\n",
    "    'l_lgb': LGBMRegressor(),\n",
    "    'l_cat': CatBoostRegressor(),\n",
    "    'l_mlp': MLPRegressor(),\n",
    "    'l_gpr': GaussianProcessRegressor(),\n",
    "}\n",
    "for model_name, mod in models_dict.items():\n",
    "    mod.fit(X_train, y_train)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_rg MSE: 0.08269732247034495\n",
      "l_rg R2: 0.2992851000775968\n",
      "l_svr MSE: 0.08119784014044083\n",
      "l_svr R2: 0.3119905853260575\n",
      "l_dt MSE: 0.14593616000272852\n",
      "l_dt R2: -0.2365532365094627\n",
      "l_rf MSE: 0.10928567428355719\n",
      "l_rf R2: 0.07399540842430719\n",
      "l_gb MSE: 0.08120066102927147\n",
      "l_gb R2: 0.31196668323617593\n",
      "l_xgb MSE: 0.0989357285936552\n",
      "l_xgb R2: 0.1616930622498306\n",
      "l_lgb MSE: 0.08408942196929682\n",
      "l_lgb R2: 0.2874894961577735\n",
      "l_cat MSE: 0.08703721466508069\n",
      "l_cat R2: 0.26251211838887545\n",
      "l_mlp MSE: 0.08240117399827362\n",
      "l_mlp R2: 0.30179443944640205\n",
      "l_gpr MSE: 0.079830757887237\n",
      "l_gpr R2: 0.32357421192512825\n"
     ]
    }
   ],
   "source": [
    "for mod_name, mod in models_dict.items():\n",
    "    print(f\"{mod_name} MSE:\", mean_squared_error(y_test, mod.predict(X_test)))\n",
    "    print(f\"{mod_name} R2:\", r2_score(y_test, mod.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_rg MSE: 0.0797895457762088\n",
      "l_rg R2: 0.31442788589102943\n",
      "l_svr MSE: 0.07766760638632851\n",
      "l_svr R2: 0.3326601299698658\n",
      "l_dt MSE: 0.0001862585804170598\n",
      "l_dt R2: 0.9983996188033755\n",
      "l_rf MSE: 0.01644666047999878\n",
      "l_rf R2: 0.8586861012227087\n",
      "l_gb MSE: 0.06364711225071931\n",
      "l_gb R2: 0.4531277891336568\n",
      "l_xgb MSE: 0.025973412549452325\n",
      "l_xgb R2: 0.7768298192585779\n",
      "l_lgb MSE: 0.06629646140915622\n",
      "l_lgb R2: 0.4303639058969134\n",
      "l_cat MSE: 0.06398253726462903\n",
      "l_cat R2: 0.4502457319208474\n",
      "l_mlp MSE: 0.08015976909137576\n",
      "l_mlp R2: 0.3112468328044091\n",
      "l_gpr MSE: 0.07634098214760159\n",
      "l_gpr R2: 0.34405882355966466\n"
     ]
    }
   ],
   "source": [
    "for mod_name, mod in models_dict.items():\n",
    "    print(f\"{mod_name} MSE:\", mean_squared_error(y_train, mod.predict(X_train)))\n",
    "    print(f\"{mod_name} R2:\", r2_score(y_train, mod.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.34055\n",
      "[1]\tvalidation_0-error:0.34055\n",
      "[2]\tvalidation_0-error:0.34055\n",
      "[3]\tvalidation_0-error:0.34500\n",
      "[4]\tvalidation_0-error:0.34796\n",
      "MSE: 0.08158296617639564\n",
      "R2: 0.3087273170160302\n"
     ]
    }
   ],
   "source": [
    "eval_set = [(X_test, y_test)]\n",
    "xgb_1 = XGBRegressor( max_depth=2,n_estimators=5, learning_rate=0.4, subsample=0.2, colsample_bytree=0.8,)\n",
    "# ,n_estimators=100,learning_rate=0.1)\n",
    "xgb_1.fit(X_train, y_train, eval_metric=\"error\", eval_set=eval_set, verbose=True)\n",
    "y_pred = xgb_1.predict(X_test)\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_emb_dict = {}\n",
    "def get_word_emb(word):\n",
    "    if word in words_emb_dict:\n",
    "        return words_emb_dict[word]\n",
    "    else:\n",
    "        words_emb_dict[word] = model.encode(word)\n",
    "        return words_emb_dict[word]\n",
    "\n",
    "def get_words_emb(words):\n",
    "    return list(map(get_words_emb, words))\n",
    "model_answers_dict = {\n",
    "    1: load_obj(f'data/essaySet_{1}_model_answers'),\n",
    "    2: load_obj(f'data/essaySet_{2}_model_answers'),\n",
    "    3: load_obj(f'data/essaySet_{3}_model_answers'),\n",
    "    4: load_obj(f'data/essaySet_{4}_model_answers'),\n",
    "    5: load_obj(f'data/essaySet_{5}_model_answers'),\n",
    "    6: load_obj(f'data/essaySet_{6}_model_answers'),\n",
    "    7: load_obj(f'data/essaySet_{7}_model_answers'),\n",
    "    8: load_obj(f'data/essaySet_{8}_model_answers'),\n",
    "    9: load_obj(f'data/essaySet_{9}_model_answers'),\n",
    "    10: load_obj(f'data/essaySet_{10}_model_answers'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df.query(f'EssaySet == {1}')[\"EssayText\"].values.tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    times = {}\n",
    "    for essay in range(1,2):\n",
    "        t = []\n",
    "        clear_output()\n",
    "        print(f\"EssaySet: {essay} ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        model_answers = model_answers_dict[essay]\n",
    "        # docs = df.query(f'EssaySet == {essay}')[\"EssayText\"].values.tolist()[:10]\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"docs cands ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        docs_candidates = list(map(lambda ans: key_words.candidates_tokens(ans,n_gram_range=(2,3)),docs))\n",
    "        print(f\"docs cands emb...\")\n",
    "        docs_candidate_emb = list(map(lambda cand: get_words_emb(cand),docs_candidates))\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"Encoding ... docs\")\n",
    "        t1 = time.perf_counter()\n",
    "        docs_emb = model.encode(docs)\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"docs keywords ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        docs_keywords = list(map(lambda x: maximal_marginal_relevance(\n",
    "            x[0].reshape(1, -1),x[1],x[2],top_n=10 ,diversity=0.8),\n",
    "            zip(docs_emb,docs_candidate_emb,docs_candidates)))\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"docs keywords emb ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        docs_keywords_emb = list(map(lambda x: get_words_emb(x),docs_keywords))\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"model keywords ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        model_candidates = list(map(lambda ans: key_words.candidates_tokens(ans,n_gram_range=(2,3)),model_answers))\n",
    "        model_candidate_emb = list(map(lambda cand: get_words_emb(cand),model_candidates))\n",
    "        keywords = list(map(lambda x: maximal_marginal_relevance(\n",
    "            x[0].reshape(1, -1),x[1],x[2],top_n=10,diversity=0.8),\n",
    "            zip(model.encode(model_answers),\n",
    "            model_candidate_emb,model_candidates)))\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        print(f\"model keywords emb ...\")\n",
    "        t1 = time.perf_counter()\n",
    "        keywords_emb = list(map(lambda x: get_words_emb(x),keywords))\n",
    "        t.append(time.perf_counter() - t1)\n",
    "\n",
    "        s = list(map(lambda model_emb: \n",
    "            list(map(lambda doc_emb: cos_sim(model_emb,doc_emb).__array__().max(axis=1), docs_keywords_emb)),keywords_emb))\n",
    "        \n",
    "        # save the results\n",
    "        np.save(f'data/results/essaySet_{essay}_keywords_scores',np.array(s))\n",
    "        times[essay] = t\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = \"data/train_phase1.tsv\"\n",
    "# df = pd.read_csv(train_path, sep=\"\\t\")\n",
    "# keywords_threshold = 0.53\n",
    "# kwrds_path = 'data/results/keys_score_0.53_essay'\n",
    "# kwrds_res = load_obj(kwrds_path)\n",
    "# siamese_scores = load_obj(\"data/results/final_siamese_scores\")\n",
    "ner_scores = load_obj(\"data/results/ner_res\")\n",
    "special_keywords_res = load_obj(\"data/results/special_keywords_res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>Score1</th>\n",
       "      <th>Score2</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>score</th>\n",
       "      <th>score_gn</th>\n",
       "      <th>score_gn_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Some additional information that we would need...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.343907</td>\n",
       "      <td>0.331842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>After reading the expirement, I realized that ...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340896</td>\n",
       "      <td>0.365264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>What you need is more trials, a control set up...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.351329</td>\n",
       "      <td>0.354158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The student should list what rock is better an...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>For the students to be able to make a replicat...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656207</td>\n",
       "      <td>0.710926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Id  EssaySet  Score1  Score2  \\\n",
       "0           0   1         1       1       1   \n",
       "1           1   2         1       1       1   \n",
       "2           2   3         1       1       1   \n",
       "3           3   4         1       0       0   \n",
       "4           4   5         1       2       2   \n",
       "\n",
       "                                           EssayText     score  score_gn  \\\n",
       "0  Some additional information that we would need...  0.333333  0.343907   \n",
       "1  After reading the expirement, I realized that ...  0.333333  0.340896   \n",
       "2  What you need is more trials, a control set up...  0.333333  0.351329   \n",
       "3  The student should list what rock is better an...  0.000000  0.000000   \n",
       "4  For the students to be able to make a replicat...  0.666667  0.656207   \n",
       "\n",
       "   score_gn_1  \n",
       "0    0.331842  \n",
       "1    0.365264  \n",
       "2    0.354158  \n",
       "3    0.089832  \n",
       "4    0.710926  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[df[\"EssaySet\"]==2][\"EssayText\"].values.tolist()\n",
    "docs1 = df[df[\"EssaySet\"]==3][\"EssayText\"].values.tolist()\n",
    "docs_emb = model.encode(docs)\n",
    "docs1_emb = model.encode(docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_answers\n",
    "ess2 = model.encode(load_obj(f'data/essaySet_{2}_model_answers'))\n",
    "ess3 = model.encode(load_obj(f'data/essaySet_{3}_model_answers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_scores = []\n",
    "\n",
    "siamese_scores.append(cos_sim(docs_emb,ess2).__array__().max(axis=1))\n",
    "siamese_scores.append(cos_sim(docs1_emb,ess3).__array__().max(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_scores = load_obj(\"data/results/ner_res\")\n",
    "special_keywords_res = load_obj(\"data/results/special_keywords_res\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = df[df[\"EssaySet\"]==2][\"score_gn_1\"].values.tolist()\n",
    "score1 = df[df[\"EssaySet\"]==3][\"score_gn_1\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_df = pd.concat([pd.DataFrame(np.concatenate([siamese_scores[0],siamese_scores[1]])),\n",
    "pd.DataFrame(np.concatenate([ner_scores[1],ner_scores[2]])),\n",
    "pd.DataFrame(np.concatenate([special_keywords_res[\"ess_2_model_answers\"],special_keywords_res[\"ess_3_model_answers\"]])),\n",
    "pd.DataFrame(np.array(score+score1))],axis=1)\n",
    "n_df.columns = ['siamese_score', 'ner_score', 'special_keywords_score','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10886717258549733\n",
      "R2: 0.0351778337275136\n"
     ]
    }
   ],
   "source": [
    "# train a regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# train the model\n",
    "X = n_df[['siamese_score', 'ner_score', 'special_keywords_score']]\n",
    "y = n_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"MSE:\", mean_squared_error(y_test, model.predict(X_test)))\n",
    "print(\"R2:\", r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10887742554349467\n",
      "R2: 0.035086968125782936\n"
     ]
    }
   ],
   "source": [
    "# rg with regularization\n",
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"MSE:\", mean_squared_error(y_test, model.predict(X_test)))\n",
    "print(\"R2:\", r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: -0.2612098601910762\n",
      "Best Hyperparameters: {'alpha': 1.6159531754886576, 'fit_intercept': True, 'normalize': True, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Ridge()\n",
    "# define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define search space\n",
    "space = dict()\n",
    "space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha'] = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize'] = [True, False]\n",
    "# define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)\n",
    "# execute search\n",
    "result = search.fit(X, y)\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.11045588508102697\n",
      "R2: 0.021098061146690106\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(**{'alpha': 1.62, 'fit_intercept': True, 'normalize': True, 'solver': 'sag'})\n",
    "model.fit(X_train, y_train)\n",
    "print(\"MSE:\", mean_squared_error(y_test, model.predict(X_test)))\n",
    "print(\"R2:\", r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "save_obj(model, 'data/results/model_rg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f876b07db73824ba94c3da26a300833b9286c0dd0d4e31723ae4574ddd9b9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
