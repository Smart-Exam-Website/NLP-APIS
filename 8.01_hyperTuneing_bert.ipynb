{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import key_words\n",
    "from sentence_transformers.util import cos_sim\n",
    "\n",
    "import pickle\n",
    "def save_obj(obj:object,name:str):\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name:str)->object:\n",
    "    ext = '.pickle'\n",
    "    with open(name + ext, 'rb') as handle:\n",
    "        return pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess_1_model_answers = load_obj(\"data/essaySet_1_model_answers\")\n",
    "ess_2_model_answers = load_obj(\"data/essaySet_2_model_answers\")\n",
    "ess_3_model_answers = load_obj(\"data/essaySet_3_model_answers\")\n",
    "ess_4_model_answers = load_obj(\"data/essaySet_4_model_answers\")\n",
    "ess_5_model_answers = load_obj(\"data/essaySet_5_model_answers\")\n",
    "ess_6_model_answers = load_obj(\"data/essaySet_6_model_answers\")\n",
    "ess_7_model_answers = load_obj(\"data/essaySet_7_model_answers\")\n",
    "ess_8_model_answers = load_obj(\"data/essaySet_8_model_answers\")\n",
    "ess_9_model_answers = load_obj(\"data/essaySet_9_model_answers\")\n",
    "ess_10_model_answers = load_obj(\"data/essaySet_10_model_answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_marginal_relevance(doc_embedding: np.ndarray,\n",
    "        word_embeddings: np.ndarray,\n",
    "        words,\n",
    "        top_n = 5,\n",
    "        diversity = 0.8):\n",
    "    \"\"\"\n",
    "    Maximal Marginal Relevance algorithm for keyword extraction\n",
    "    * from KeyBERT repository on github\n",
    "\n",
    "    Args:\n",
    "        doc_embedding (numpy.ndarray): embedding of shape (1, 768)\n",
    "        word_embeddings (numpy.ndarray): embedding of shape (N, 768)\n",
    "        words (List[str]): list of words\n",
    "        top_n (Optional[int]): number of top words to extract\n",
    "        diversity (Optional[float]): diversity of top words to extract\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: list of top_n words with their scores\n",
    "    \"\"\"\n",
    "    # make sure 2d array\n",
    "    if doc_embedding.ndim == 1:\n",
    "        doc_embedding = doc_embedding.reshape(1, -1)\n",
    "\n",
    "    # Extract similarity within words, and between words and the document\n",
    "    # word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    # word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    word_doc_similarity = np.array(cos_sim(word_embeddings, doc_embedding)).clip(-1, 1).round(6)\n",
    "    word_similarity = np.array(cos_sim(word_embeddings, word_embeddings)).clip(-1, 1).round(6)\n",
    "\n",
    "    # Initialize candidates and already choose best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate maximal_marginal_relevance\n",
    "        mmr = (1-diversity) * candidate_similarities -\\\n",
    "            diversity * target_similarities.reshape(-1, 1)\n",
    "        # if return mmr is empty\n",
    "        if mmr.size == 0:\n",
    "            continue\n",
    "        mmr = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr)\n",
    "        candidates_idx.remove(mmr)\n",
    "    return [words[idx] for idx in keywords_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_keys_div(ind,essay,top_n=5,diversities=[0.8]):\n",
    "    for div in diversities:\n",
    "        keywords = list(map(lambda x: maximal_marginal_relevance(x[0].reshape(1, -1),x[1],x[2],top_n=top_n,diversity=div),\n",
    "            zip(emb_dict[f'ess_{essay}_model_answers_emb'],\n",
    "            model_candidate_emb,model_candidates)))\n",
    "        print(div,keywords[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_f1_k(assigned, extracted, k):\n",
    "    \"\"\"\n",
    "    Computes the exatch match f1 measure at k.\n",
    "    Arguments\n",
    "    ---------\n",
    "    assigned  : A list of human assigned keyphrases.\n",
    "    extracted : A list of extracted keyphrases.\n",
    "    k         : int\n",
    "                The maximum number of extracted keyphrases.\n",
    "    Returned value\n",
    "    --------------\n",
    "              : double\n",
    "    \"\"\"\n",
    "    # Exit early, if one of the lists or both are empty.\n",
    "    if not assigned or not extracted:\n",
    "        return 0.0\n",
    "\n",
    "    precision_k = len(set(assigned) & set(extracted)) / k\n",
    "    recall_k = len(set(assigned) & set(extracted)) / len(assigned)\n",
    "    return (\n",
    "        2 * precision_k * recall_k / (precision_k + recall_k)\n",
    "        if precision_k and recall_k else 0.0\n",
    "    )\n",
    "\n",
    "def partial_f1_k(assigned, extracted, k):\n",
    "    \"\"\"\n",
    "    Computes the exatch match f1 measure at k.\n",
    "    Arguments\n",
    "    ---------\n",
    "    assigned  : A list of human assigned keyphrases.\n",
    "    extracted : A list of extracted keyphrases.\n",
    "    k         : int\n",
    "                The maximum number of extracted keyphrases.\n",
    "    Returned value\n",
    "    --------------\n",
    "              : double\n",
    "    \"\"\"\n",
    "    # Exit early, if one of the lists or both are empty.\n",
    "    if not assigned or not extracted:\n",
    "        return 0.0\n",
    "\n",
    "    # Store the longest keyphrases first.\n",
    "    assigned_sets = sorted([set(keyword.split()) for keyword in assigned], key = len, reverse = True)\n",
    "    extracted_sets = sorted([set(keyword.split()) for keyword in extracted], key = len, reverse = True)\n",
    "\n",
    "    # This list stores True, if the assigned keyphrase has been matched earlier.\n",
    "    # To avoid counting duplicate matches.\n",
    "    assigned_matches = [False for assigned_set in assigned_sets]\n",
    "\n",
    "    # For each extracted keyphrase, find the closest match, \n",
    "    # which is the assigned keyphrase it has the most words in common.\n",
    "    for extracted_set in extracted_sets:\n",
    "        all_matches = [(i, len(assigned_set & extracted_set)) for i, assigned_set in enumerate(assigned_sets)]\n",
    "        closest_match = sorted(all_matches, key = lambda x: x[1], reverse = True)[0]\n",
    "        assigned_matches[closest_match[0]] = True\n",
    "\n",
    "    # Calculate the precision and recall metrics based on the partial matches.\n",
    "    partial_matches = assigned_matches.count(True)  \n",
    "    precision_k = partial_matches / k\n",
    "    recall_k = partial_matches / len(assigned)\n",
    "    \n",
    "    return (\n",
    "        2 * precision_k * recall_k / (precision_k + recall_k)\n",
    "        if precision_k and recall_k else 0.0\n",
    "    )\n",
    "\n",
    "def f1_metric_k(assigned, extracted, k, partial_match = True):\n",
    "    \"\"\"\n",
    "    Wrapper function that calculates either the exact\n",
    "    or the partial match f1 metric.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        partial_f1_k(assigned, extracted, k) \n",
    "        if partial_match else exact_f1_k(assigned, extracted, k)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6153846153846153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigned = ['replicate experiment need', 'containers use vinegar', 'bit directions specific', 'step procedure little', 'know samples step', 'say size', 'little confusing', 'experiment want little', 'container allow replicate']\n",
    "assigned = [\"know what the samples\", \"little bit more directions and be more specific\" , \"size containers\", \"how much vinegar to add\"]\n",
    "extracted = ['replicate experiment need', 'want say size', 'containers use vinegar', 'procedure little', 'bit directions specific', 'need know', 'know samples step', 'add container allow', 'want little bit']\n",
    "print(len(extracted))\n",
    "# extracted = [ \"know what the samples\", \"little bit more directions and be more specific\", \"size containers\", \"how much vinegar to add\",]\n",
    "f1_metric_k(assigned, extracted, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keys_score(assigned,essay,diversities=np.arange(0.3,1,0.05).round(3).tolist(),top_n=10):\n",
    "    f1_metric_k_scores = {}\n",
    "    model_candidates = key_words.candidates_tokens(essay,n_gram_range=(2,3))\n",
    "    model_candidate_emb = list(map(lambda cand: model.encode(cand),model_candidates))\n",
    "    for div in diversities:\n",
    "        keywords = maximal_marginal_relevance(model.encode(essay).reshape(1, -1),model_candidate_emb,model_candidates,top_n=top_n,diversity=div)\n",
    "        f1_metric_k_scores[div] = round(f1_metric_k(assigned,keywords,len(keywords),partial_match=True),3)\n",
    "    return f1_metric_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_2 = [\"need to determine the mass of four different samples\", \"name and list the samples that they plan on using\",\n",
    "\"say to pour vinegar\",\"how much vinegar we should pour\", \"rinse each sample with distilled water\",\n",
    "\"how much water should we use and how long should we rinse.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(ls_ls):\n",
    "    out = []\n",
    "    for ls in ls_ls:\n",
    "        if isinstance(ls, list):\n",
    "            out.append(ls[0])\n",
    "        else:\n",
    "            out.append(ls)\n",
    "    return out\n",
    "\n",
    "def score_f1(assigned,essays):\n",
    "    f1_metric_k_scores = []\n",
    "    for i in essays:\n",
    "        ess = keys_score(assigned,i)\n",
    "        # get max 3 values\n",
    "        scores = sorted(ess.items(), key=lambda x: x[1], reverse=True)[:2]\n",
    "        f1_metric_k_scores.append(scores)\n",
    "    \n",
    "    f1_metric_k_scores = flatten(f1_metric_k_scores)\n",
    "\n",
    "    return f1_metric_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = score_f1(assigned_2,ess_1_model_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 0.625), (0.7, 0.625), (0.55, 0.75), (0.3, 0.625), (0.45, 0.625)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[1] > 0.5, set(out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.4, 0.286),\n",
       " (0.4, 0.286),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.55, 0.286),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.4, 0.286),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.143),\n",
       " (0.3, 0.286),\n",
       " (0.3, 0.286)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_9 =[\"has a very effective way of organizing the the article\", \"Once grabbing the readers attention\",\"Space Junk?\",\"Crash Course\"]\n",
    "out_9 = score_f1(assigned_9,ess_9_model_answers)\n",
    "out_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[1] > 0.5, set(out_9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3, 0.429),\n",
       " (0.3, 0.375),\n",
       " (0.3, 0.333),\n",
       " (0.3, 0.353),\n",
       " (0.3, 0.235),\n",
       " (0.3, 0.286),\n",
       " (0.3, 0.375),\n",
       " (0.3, 0.353),\n",
       " (0.3, 0.353),\n",
       " (0.5, 0.353),\n",
       " (0.4, 0.353),\n",
       " (0.3, 0.471),\n",
       " (0.55, 0.471),\n",
       " (0.3, 0.353),\n",
       " (0.3, 0.353),\n",
       " (0.3, 0.235),\n",
       " (0.3, 0.471),\n",
       " (0.35, 0.353),\n",
       " (0.3, 0.588),\n",
       " (0.45, 0.588),\n",
       " (0.35, 0.353),\n",
       " (0.45, 0.588)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned__3 =[\"know the size\",\"samples are put in\",\"know tha amount of samples\",\n",
    "\"to put in each container\",\"obtain tha same starting mass\",\"Another factor amount no vinegar\",\n",
    "\"location where the samples are drying and amount of sunlight.\"]\n",
    "out_3 = score_f1(assigned__3,ess_1_model_answers)\n",
    "out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3, 0.588), (0.45, 0.588)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[1] > 0.5, set(out_3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The word \"invasive\" helps to create a debate in the article. Invasive species are animals that are introduced into an envoriment and thrive in it possible affecting other animals. The scientist feels the term \"invasive species is unfair\", referring to pythons. Biologists, however feel invasive species are major threats to biodiversity. The word \"invasive\" helps to provide debate on this article.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ess_4_model_answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.45, 0.316),\n",
       " (0.6, 0.632),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.316),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.35, 0.421),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.316),\n",
       " (0.65, 0.316),\n",
       " (0.3, 0.211),\n",
       " (0.3, 0.211),\n",
       " (0.35, 0.316),\n",
       " (0.4, 0.316),\n",
       " (0.4, 0.316),\n",
       " (0.3, 0.211),\n",
       " (0.45, 0.421)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_4 = [\"\\\"invasive\\\"\", \"helps to create a debate\",\"invasive species is unfair\",\n",
    "    \"referring to pythons.\",\" Biologists\",\"threats to biodiversity\",\"an envoriment and thrive\"\n",
    "    ,\"envoriment thrive\",\"affecting other animals\" ]\n",
    "out_4 = score_f1(assigned_4,ess_4_model_answers)\n",
    "out_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.6, 0.632)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x[1] > 0.5, set(out_4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET DIVERSITY TO 0.65"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f876b07db73824ba94c3da26a300833b9286c0dd0d4e31723ae4574ddd9b9bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
